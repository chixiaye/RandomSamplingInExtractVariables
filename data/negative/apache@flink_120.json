{
  "id" : 120,
  "expression" : "orcSelectedFields",
  "projectName" : "apache@flink",
  "commitID" : "f8cb19e70ca7da6423dfb01b97e05c4d520c9fde",
  "filePath" : "/flink-formats/flink-orc/src/main/java/org/apache/flink/orc/OrcColumnarRowInputFormat.java",
  "occurrences" : 1,
  "isArithmeticExpression" : 0,
  "isGetTypeMethod" : 0,
  "expressionList" : [ {
    "nodeContext" : "orcSelectedFields",
    "nodeType" : "SimpleName",
    "nodePosition" : {
      "charLength" : 17,
      "startLineNumber" : 176,
      "startColumnNumber" : 16,
      "endLineNumber" : 176,
      "endColumnNumber" : 33
    },
    "astNodeNumber" : 1,
    "astHeight" : 1,
    "parentDataList" : [ {
      "locationInParent" : "ChildProperty[org.eclipse.jdt.core.dom.ReturnStatement,expression]",
      "nodePosition" : {
        "charLength" : 604,
        "startLineNumber" : 172,
        "startColumnNumber" : 15,
        "endLineNumber" : 184,
        "endColumnNumber" : 72
      },
      "nodeContext" : "new OrcColumnarRowInputFormat<>(shim,hadoopConfig,convertToOrcTypeWithPart(tableFieldNames,tableFieldTypes,partitionKeys),orcSelectedFields,conjunctPredicates,batchSize,batchGenerator,rowTypeInfoFactory.apply(new RowType(Arrays.stream(selectedFields).mapToObj(i -> tableType.getFields().get(i)).collect(Collectors.toList()))))",
      "nodeType" : "ClassInstanceCreation",
      "astNodeNumber" : 41,
      "astHeight" : 9
    }, {
      "locationInParent" : "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
      "nodePosition" : {
        "charLength" : 612,
        "startLineNumber" : 172,
        "startColumnNumber" : 8,
        "endLineNumber" : 184,
        "endColumnNumber" : 73
      },
      "nodeContext" : "return new OrcColumnarRowInputFormat<>(shim,hadoopConfig,convertToOrcTypeWithPart(tableFieldNames,tableFieldTypes,partitionKeys),orcSelectedFields,conjunctPredicates,batchSize,batchGenerator,rowTypeInfoFactory.apply(new RowType(Arrays.stream(selectedFields).mapToObj(i -> tableType.getFields().get(i)).collect(Collectors.toList()))));\n",
      "nodeType" : "ReturnStatement",
      "astNodeNumber" : 42,
      "astHeight" : 10
    }, {
      "locationInParent" : "ChildProperty[org.eclipse.jdt.core.dom.MethodDeclaration,body]",
      "nodePosition" : {
        "charLength" : 2361,
        "startLineNumber" : 142,
        "startColumnNumber" : 84,
        "endLineNumber" : 185,
        "endColumnNumber" : 5
      },
      "nodeContext" : "{\n  String[] tableFieldNames=tableType.getFieldNames().toArray(new String[0]);\n  LogicalType[] tableFieldTypes=tableType.getChildren().toArray(new LogicalType[0]);\n  List<String> orcFieldNames=getNonPartNames(tableFieldNames,partitionKeys);\n  int[] orcSelectedFields=getSelectedOrcFields(tableFieldNames,selectedFields,orcFieldNames);\n  ColumnBatchFactory<VectorizedRowBatch,SplitT> batchGenerator=(  SplitT split,  VectorizedRowBatch rowBatch) -> {\n    ColumnVector[] vectors=new ColumnVector[selectedFields.length];\n    for (int i=0; i < vectors.length; i++) {\n      String name=tableFieldNames[selectedFields[i]];\n      LogicalType type=tableFieldTypes[selectedFields[i]];\n      vectors[i]=partitionKeys.contains(name) ? createFlinkVectorFromConstant(type,extractor.extract(split,name,type),batchSize) : createFlinkVector(rowBatch.cols[orcFieldNames.indexOf(name)],type);\n    }\n    return new VectorizedColumnBatch(vectors);\n  }\n;\n  return new OrcColumnarRowInputFormat<>(shim,hadoopConfig,convertToOrcTypeWithPart(tableFieldNames,tableFieldTypes,partitionKeys),orcSelectedFields,conjunctPredicates,batchSize,batchGenerator,rowTypeInfoFactory.apply(new RowType(Arrays.stream(selectedFields).mapToObj(i -> tableType.getFields().get(i)).collect(Collectors.toList()))));\n}\n",
      "nodeType" : "Block",
      "astNodeNumber" : 207,
      "astHeight" : 14
    }, {
      "locationInParent" : "ChildListProperty[org.eclipse.jdt.core.dom.TypeDeclaration,bodyDeclarations]",
      "nodePosition" : {
        "charLength" : 3114,
        "startLineNumber" : 128,
        "startColumnNumber" : 4,
        "endLineNumber" : 185,
        "endColumnNumber" : 5
      },
      "nodeContext" : "/** \n * Create a partitioned  {@link OrcColumnarRowInputFormat}, the partition columns can be generated by split.\n */\npublic static <SplitT extends FileSourceSplit>OrcColumnarRowInputFormat<VectorizedRowBatch,SplitT> createPartitionedFormat(OrcShim<VectorizedRowBatch> shim,Configuration hadoopConfig,RowType tableType,List<String> partitionKeys,PartitionFieldExtractor<SplitT> extractor,int[] selectedFields,List<OrcFilters.Predicate> conjunctPredicates,int batchSize,Function<RowType,TypeInformation<RowData>> rowTypeInfoFactory){\n  String[] tableFieldNames=tableType.getFieldNames().toArray(new String[0]);\n  LogicalType[] tableFieldTypes=tableType.getChildren().toArray(new LogicalType[0]);\n  List<String> orcFieldNames=getNonPartNames(tableFieldNames,partitionKeys);\n  int[] orcSelectedFields=getSelectedOrcFields(tableFieldNames,selectedFields,orcFieldNames);\n  ColumnBatchFactory<VectorizedRowBatch,SplitT> batchGenerator=(  SplitT split,  VectorizedRowBatch rowBatch) -> {\n    ColumnVector[] vectors=new ColumnVector[selectedFields.length];\n    for (int i=0; i < vectors.length; i++) {\n      String name=tableFieldNames[selectedFields[i]];\n      LogicalType type=tableFieldTypes[selectedFields[i]];\n      vectors[i]=partitionKeys.contains(name) ? createFlinkVectorFromConstant(type,extractor.extract(split,name,type),batchSize) : createFlinkVector(rowBatch.cols[orcFieldNames.indexOf(name)],type);\n    }\n    return new VectorizedColumnBatch(vectors);\n  }\n;\n  return new OrcColumnarRowInputFormat<>(shim,hadoopConfig,convertToOrcTypeWithPart(tableFieldNames,tableFieldTypes,partitionKeys),orcSelectedFields,conjunctPredicates,batchSize,batchGenerator,rowTypeInfoFactory.apply(new RowType(Arrays.stream(selectedFields).mapToObj(i -> tableType.getFields().get(i)).collect(Collectors.toList()))));\n}\n",
      "nodeType" : "MethodDeclaration",
      "astNodeNumber" : 281,
      "astHeight" : 15
    } ],
    "currentLineData" : {
      "locationInParent" : "ChildProperty[org.eclipse.jdt.core.dom.ReturnStatement,expression]",
      "nodePosition" : {
        "charLength" : 604,
        "startLineNumber" : 172,
        "startColumnNumber" : 15,
        "endLineNumber" : 184,
        "endColumnNumber" : 72
      },
      "nodeContext" : "new OrcColumnarRowInputFormat<>(shim,hadoopConfig,convertToOrcTypeWithPart(tableFieldNames,tableFieldTypes,partitionKeys),orcSelectedFields,conjunctPredicates,batchSize,batchGenerator,rowTypeInfoFactory.apply(new RowType(Arrays.stream(selectedFields).mapToObj(i -> tableType.getFields().get(i)).collect(Collectors.toList()))))",
      "nodeType" : "ClassInstanceCreation",
      "astNodeNumber" : 41,
      "astHeight" : 9
    },
    "tokenLength" : 1,
    "type" : "int[]"
  } ],
  "positionList" : [ {
    "charLength" : 17,
    "startLineNumber" : 176,
    "startColumnNumber" : 16,
    "endLineNumber" : 176,
    "endColumnNumber" : 33
  } ],
  "layoutRelationDataList" : [ ]
}