{
  "id" : 439,
  "expression" : "e.getMessage()",
  "projectName" : "antlr@antlr4",
  "commitID" : "f2b93e550cd912be3973743d09206db98f4092c9",
  "filePath" : "/tool/src/org/antlr/v4/parse/TokenVocabParser.java",
  "occurrences" : 1,
  "isArithmeticExpression" : 0,
  "isGetTypeMethod" : 0,
  "expressionList" : [ {
    "nodeContext" : "e.getMessage()",
    "nodeType" : "MethodInvocation",
    "nodePosition" : {
      "charLength" : 14,
      "startLineNumber" : 109,
      "startColumnNumber" : 10,
      "endLineNumber" : 109,
      "endColumnNumber" : 24
    },
    "astNodeNumber" : 3,
    "astHeight" : 2,
    "parentDataList" : [ {
      "locationInParent" : "ChildProperty[org.eclipse.jdt.core.dom.ExpressionStatement,expression]",
      "nodePosition" : {
        "charLength" : 120,
        "startLineNumber" : 106,
        "startColumnNumber" : 3,
        "endLineNumber" : 109,
        "endColumnNumber" : 25
      },
      "nodeContext" : "tool.errMgr.toolError(ErrorType.ERROR_READING_TOKENS_FILE,e,fullFile,e.getMessage())",
      "nodeType" : "MethodInvocation",
      "astNodeNumber" : 13,
      "astHeight" : 3
    }, {
      "locationInParent" : "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
      "nodePosition" : {
        "charLength" : 121,
        "startLineNumber" : 106,
        "startColumnNumber" : 3,
        "endLineNumber" : 109,
        "endColumnNumber" : 26
      },
      "nodeContext" : "tool.errMgr.toolError(ErrorType.ERROR_READING_TOKENS_FILE,e,fullFile,e.getMessage());\n",
      "nodeType" : "ExpressionStatement",
      "astNodeNumber" : 14,
      "astHeight" : 4
    }, {
      "locationInParent" : "ChildProperty[org.eclipse.jdt.core.dom.CatchClause,body]",
      "nodePosition" : {
        "charLength" : 132,
        "startLineNumber" : 105,
        "startColumnNumber" : 22,
        "endLineNumber" : 110,
        "endColumnNumber" : 3
      },
      "nodeContext" : "{\n  tool.errMgr.toolError(ErrorType.ERROR_READING_TOKENS_FILE,e,fullFile,e.getMessage());\n}\n",
      "nodeType" : "Block",
      "astNodeNumber" : 15,
      "astHeight" : 5
    }, {
      "locationInParent" : "ChildListProperty[org.eclipse.jdt.core.dom.TryStatement,catchClauses]",
      "nodePosition" : {
        "charLength" : 152,
        "startLineNumber" : 105,
        "startColumnNumber" : 2,
        "endLineNumber" : 110,
        "endColumnNumber" : 3
      },
      "nodeContext" : "catch (Exception e) {\n  tool.errMgr.toolError(ErrorType.ERROR_READING_TOKENS_FILE,e,fullFile,e.getMessage());\n}\n",
      "nodeType" : "CatchClause",
      "astNodeNumber" : 20,
      "astHeight" : 6
    }, {
      "locationInParent" : "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
      "nodePosition" : {
        "charLength" : 2451,
        "startLineNumber" : 44,
        "startColumnNumber" : 2,
        "endLineNumber" : 121,
        "endColumnNumber" : 3
      },
      "nodeContext" : "try {\n  Pattern tokenDefPattern=Pattern.compile(\"([^\\n]+?)[ \\\\t]*?=[ \\\\t]*?([0-9]+)\");\n  fis=new FileInputStream(fullFile);\n  InputStreamReader isr;\n  if (tool.grammarEncoding != null) {\n    isr=new InputStreamReader(fis,tool.grammarEncoding);\n  }\n else {\n    isr=new InputStreamReader(fis);\n  }\n  br=new BufferedReader(isr);\n  String tokenDef=br.readLine();\n  int lineNum=1;\n  while (tokenDef != null) {\n    Matcher matcher=tokenDefPattern.matcher(tokenDef);\n    if (matcher.find()) {\n      String tokenID=matcher.group(1);\n      String tokenTypeS=matcher.group(2);\n      int tokenType;\n      try {\n        tokenType=Integer.valueOf(tokenTypeS);\n      }\n catch (      NumberFormatException nfe) {\n        tool.errMgr.toolError(ErrorType.TOKENS_FILE_SYNTAX_ERROR,vocabName + CodeGenerator.VOCAB_FILE_EXTENSION,\" bad token type: \" + tokenTypeS,lineNum);\n        tokenType=Token.INVALID_TOKEN_TYPE;\n      }\n      tool.log(\"grammar\",\"import \" + tokenID + \"=\"+ tokenType);\n      tokens.put(tokenID,tokenType);\n      maxTokenType=Math.max(maxTokenType,tokenType);\n      lineNum++;\n    }\n else {\n      if (tokenDef.length() > 0) {\n        tool.errMgr.toolError(ErrorType.TOKENS_FILE_SYNTAX_ERROR,vocabName + CodeGenerator.VOCAB_FILE_EXTENSION,\" bad token def: \" + tokenDef,lineNum);\n      }\n    }\n    tokenDef=br.readLine();\n  }\n}\n catch (FileNotFoundException fnfe) {\n  GrammarAST inTree=g.ast.getOptionAST(\"tokenVocab\");\n  String inTreeValue=inTree.getToken().getText();\n  if (vocabName.equals(inTreeValue)) {\n    tool.errMgr.grammarError(ErrorType.CANNOT_FIND_TOKENS_FILE_REFD_IN_GRAMMAR,g.fileName,inTree.getToken(),fullFile);\n  }\n else {\n    tool.errMgr.toolError(ErrorType.CANNOT_FIND_TOKENS_FILE_GIVEN_ON_CMDLINE,fullFile,g.name);\n  }\n}\ncatch (Exception e) {\n  tool.errMgr.toolError(ErrorType.ERROR_READING_TOKENS_FILE,e,fullFile,e.getMessage());\n}\n finally {\n  try {\n    if (br != null)     br.close();\n  }\n catch (  IOException ioe) {\n    tool.errMgr.toolError(ErrorType.ERROR_READING_TOKENS_FILE,ioe,fullFile,ioe.getMessage());\n  }\n}\n",
      "nodeType" : "TryStatement",
      "astNodeNumber" : 321,
      "astHeight" : 14
    }, {
      "locationInParent" : "ChildProperty[org.eclipse.jdt.core.dom.MethodDeclaration,body]",
      "nodePosition" : {
        "charLength" : 2754,
        "startLineNumber" : 36,
        "startColumnNumber" : 35,
        "endLineNumber" : 123,
        "endColumnNumber" : 2
      },
      "nodeContext" : "{\n  Map<String,Integer> tokens=new LinkedHashMap<String,Integer>();\n  int maxTokenType=-1;\n  File fullFile=getImportedVocabFile();\n  FileInputStream fis=null;\n  BufferedReader br=null;\n  Tool tool=g.tool;\n  String vocabName=g.getOptionString(\"tokenVocab\");\n  try {\n    Pattern tokenDefPattern=Pattern.compile(\"([^\\n]+?)[ \\\\t]*?=[ \\\\t]*?([0-9]+)\");\n    fis=new FileInputStream(fullFile);\n    InputStreamReader isr;\n    if (tool.grammarEncoding != null) {\n      isr=new InputStreamReader(fis,tool.grammarEncoding);\n    }\n else {\n      isr=new InputStreamReader(fis);\n    }\n    br=new BufferedReader(isr);\n    String tokenDef=br.readLine();\n    int lineNum=1;\n    while (tokenDef != null) {\n      Matcher matcher=tokenDefPattern.matcher(tokenDef);\n      if (matcher.find()) {\n        String tokenID=matcher.group(1);\n        String tokenTypeS=matcher.group(2);\n        int tokenType;\n        try {\n          tokenType=Integer.valueOf(tokenTypeS);\n        }\n catch (        NumberFormatException nfe) {\n          tool.errMgr.toolError(ErrorType.TOKENS_FILE_SYNTAX_ERROR,vocabName + CodeGenerator.VOCAB_FILE_EXTENSION,\" bad token type: \" + tokenTypeS,lineNum);\n          tokenType=Token.INVALID_TOKEN_TYPE;\n        }\n        tool.log(\"grammar\",\"import \" + tokenID + \"=\"+ tokenType);\n        tokens.put(tokenID,tokenType);\n        maxTokenType=Math.max(maxTokenType,tokenType);\n        lineNum++;\n      }\n else {\n        if (tokenDef.length() > 0) {\n          tool.errMgr.toolError(ErrorType.TOKENS_FILE_SYNTAX_ERROR,vocabName + CodeGenerator.VOCAB_FILE_EXTENSION,\" bad token def: \" + tokenDef,lineNum);\n        }\n      }\n      tokenDef=br.readLine();\n    }\n  }\n catch (  FileNotFoundException fnfe) {\n    GrammarAST inTree=g.ast.getOptionAST(\"tokenVocab\");\n    String inTreeValue=inTree.getToken().getText();\n    if (vocabName.equals(inTreeValue)) {\n      tool.errMgr.grammarError(ErrorType.CANNOT_FIND_TOKENS_FILE_REFD_IN_GRAMMAR,g.fileName,inTree.getToken(),fullFile);\n    }\n else {\n      tool.errMgr.toolError(ErrorType.CANNOT_FIND_TOKENS_FILE_GIVEN_ON_CMDLINE,fullFile,g.name);\n    }\n  }\ncatch (  Exception e) {\n    tool.errMgr.toolError(ErrorType.ERROR_READING_TOKENS_FILE,e,fullFile,e.getMessage());\n  }\n finally {\n    try {\n      if (br != null)       br.close();\n    }\n catch (    IOException ioe) {\n      tool.errMgr.toolError(ErrorType.ERROR_READING_TOKENS_FILE,ioe,fullFile,ioe.getMessage());\n    }\n  }\n  return tokens;\n}\n",
      "nodeType" : "Block",
      "astNodeNumber" : 384,
      "astHeight" : 15
    }, {
      "locationInParent" : "ChildListProperty[org.eclipse.jdt.core.dom.TypeDeclaration,bodyDeclarations]",
      "nodePosition" : {
        "charLength" : 2862,
        "startLineNumber" : 35,
        "startColumnNumber" : 1,
        "endLineNumber" : 123,
        "endColumnNumber" : 2
      },
      "nodeContext" : "/** \n * Load a vocab file  {@code <vocabName>.tokens} and return mapping. \n */\npublic Map<String,Integer> load(){\n  Map<String,Integer> tokens=new LinkedHashMap<String,Integer>();\n  int maxTokenType=-1;\n  File fullFile=getImportedVocabFile();\n  FileInputStream fis=null;\n  BufferedReader br=null;\n  Tool tool=g.tool;\n  String vocabName=g.getOptionString(\"tokenVocab\");\n  try {\n    Pattern tokenDefPattern=Pattern.compile(\"([^\\n]+?)[ \\\\t]*?=[ \\\\t]*?([0-9]+)\");\n    fis=new FileInputStream(fullFile);\n    InputStreamReader isr;\n    if (tool.grammarEncoding != null) {\n      isr=new InputStreamReader(fis,tool.grammarEncoding);\n    }\n else {\n      isr=new InputStreamReader(fis);\n    }\n    br=new BufferedReader(isr);\n    String tokenDef=br.readLine();\n    int lineNum=1;\n    while (tokenDef != null) {\n      Matcher matcher=tokenDefPattern.matcher(tokenDef);\n      if (matcher.find()) {\n        String tokenID=matcher.group(1);\n        String tokenTypeS=matcher.group(2);\n        int tokenType;\n        try {\n          tokenType=Integer.valueOf(tokenTypeS);\n        }\n catch (        NumberFormatException nfe) {\n          tool.errMgr.toolError(ErrorType.TOKENS_FILE_SYNTAX_ERROR,vocabName + CodeGenerator.VOCAB_FILE_EXTENSION,\" bad token type: \" + tokenTypeS,lineNum);\n          tokenType=Token.INVALID_TOKEN_TYPE;\n        }\n        tool.log(\"grammar\",\"import \" + tokenID + \"=\"+ tokenType);\n        tokens.put(tokenID,tokenType);\n        maxTokenType=Math.max(maxTokenType,tokenType);\n        lineNum++;\n      }\n else {\n        if (tokenDef.length() > 0) {\n          tool.errMgr.toolError(ErrorType.TOKENS_FILE_SYNTAX_ERROR,vocabName + CodeGenerator.VOCAB_FILE_EXTENSION,\" bad token def: \" + tokenDef,lineNum);\n        }\n      }\n      tokenDef=br.readLine();\n    }\n  }\n catch (  FileNotFoundException fnfe) {\n    GrammarAST inTree=g.ast.getOptionAST(\"tokenVocab\");\n    String inTreeValue=inTree.getToken().getText();\n    if (vocabName.equals(inTreeValue)) {\n      tool.errMgr.grammarError(ErrorType.CANNOT_FIND_TOKENS_FILE_REFD_IN_GRAMMAR,g.fileName,inTree.getToken(),fullFile);\n    }\n else {\n      tool.errMgr.toolError(ErrorType.CANNOT_FIND_TOKENS_FILE_GIVEN_ON_CMDLINE,fullFile,g.name);\n    }\n  }\ncatch (  Exception e) {\n    tool.errMgr.toolError(ErrorType.ERROR_READING_TOKENS_FILE,e,fullFile,e.getMessage());\n  }\n finally {\n    try {\n      if (br != null)       br.close();\n    }\n catch (    IOException ioe) {\n      tool.errMgr.toolError(ErrorType.ERROR_READING_TOKENS_FILE,ioe,fullFile,ioe.getMessage());\n    }\n  }\n  return tokens;\n}\n",
      "nodeType" : "MethodDeclaration",
      "astNodeNumber" : 395,
      "astHeight" : 16
    } ],
    "currentLineData" : {
      "locationInParent" : "ChildProperty[org.eclipse.jdt.core.dom.ExpressionStatement,expression]",
      "nodePosition" : {
        "charLength" : 120,
        "startLineNumber" : 106,
        "startColumnNumber" : 3,
        "endLineNumber" : 109,
        "endColumnNumber" : 25
      },
      "nodeContext" : "tool.errMgr.toolError(ErrorType.ERROR_READING_TOKENS_FILE,e,fullFile,e.getMessage())",
      "nodeType" : "MethodInvocation",
      "astNodeNumber" : 13,
      "astHeight" : 3
    },
    "tokenLength" : 2,
    "type" : "java.lang.String"
  } ],
  "positionList" : [ {
    "charLength" : 14,
    "startLineNumber" : 109,
    "startColumnNumber" : 10,
    "endLineNumber" : 109,
    "endColumnNumber" : 24
  } ],
  "layoutRelationDataList" : [ ]
}