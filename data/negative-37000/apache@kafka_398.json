{
  "id" : 398,
  "expression" : "sourceStream.selectKey((k,v) -> keyFunction.apply(v))",
  "projectName" : "apache@kafka",
  "commitID" : "539f006e65d9060cd46a4052d1b70f2312d8ca34",
  "filePath" : "/streams/src/test/java/org/apache/kafka/streams/tests/StreamsOptimizedTest.java",
  "occurrences" : 1,
  "isArithmeticExpression" : 0,
  "isGetTypeMethod" : 0,
  "expressionList" : [ {
    "nodeContext" : "sourceStream.selectKey((k,v) -> keyFunction.apply(v))",
    "nodeType" : "MethodInvocation",
    "nodePosition" : {
      "charLength" : 54,
      "startLineNumber" : 82,
      "startColumnNumber" : 53,
      "endLineNumber" : 82,
      "endColumnNumber" : 107
    },
    "astNodeNumber" : 12,
    "astHeight" : 4,
    "parentDataList" : [ {
      "locationInParent" : "ChildListProperty[org.eclipse.jdt.core.dom.VariableDeclarationStatement,fragments]",
      "nodePosition" : {
        "charLength" : 69,
        "startLineNumber" : 82,
        "startColumnNumber" : 38,
        "endLineNumber" : 82,
        "endColumnNumber" : 107
      },
      "nodeContext" : "mappedStream=sourceStream.selectKey((k,v) -> keyFunction.apply(v))",
      "nodeType" : "VariableDeclarationFragment",
      "astNodeNumber" : 14,
      "astHeight" : 5
    }, {
      "locationInParent" : "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
      "nodePosition" : {
        "charLength" : 100,
        "startLineNumber" : 82,
        "startColumnNumber" : 8,
        "endLineNumber" : 82,
        "endColumnNumber" : 108
      },
      "nodeContext" : "final KStream<String,String> mappedStream=sourceStream.selectKey((k,v) -> keyFunction.apply(v));\n",
      "nodeType" : "VariableDeclarationStatement",
      "astNodeNumber" : 23,
      "astHeight" : 6
    }, {
      "locationInParent" : "ChildProperty[org.eclipse.jdt.core.dom.MethodDeclaration,body]",
      "nodePosition" : {
        "charLength" : 4570,
        "startLineNumber" : 53,
        "startColumnNumber" : 66,
        "endLineNumber" : 144,
        "endColumnNumber" : 5
      },
      "nodeContext" : "{\n  if (args.length < 1) {\n    System.err.println(\"StreamsOptimizedTest requires one argument (properties-file) but no provided: \");\n  }\n  final String propFileName=args[0];\n  final Properties streamsProperties=Utils.loadProps(propFileName);\n  System.out.println(\"StreamsTest instance started StreamsOptimizedTest\");\n  System.out.println(\"props=\" + streamsProperties);\n  final String inputTopic=(String)Objects.requireNonNull(streamsProperties.remove(\"input.topic\"));\n  final String aggregationTopic=(String)Objects.requireNonNull(streamsProperties.remove(\"aggregation.topic\"));\n  final String reduceTopic=(String)Objects.requireNonNull(streamsProperties.remove(\"reduce.topic\"));\n  final String joinTopic=(String)Objects.requireNonNull(streamsProperties.remove(\"join.topic\"));\n  final Pattern repartitionTopicPattern=Pattern.compile(\"Sink: .*-repartition\");\n  final Initializer<Integer> initializer=() -> 0;\n  final Aggregator<String,String,Integer> aggregator=(k,v,agg) -> agg + v.length();\n  final Reducer<String> reducer=(v1,v2) -> Integer.toString(Integer.parseInt(v1) + Integer.parseInt(v2));\n  final Function<String,String> keyFunction=s -> Integer.toString(Integer.parseInt(s) % 9);\n  final StreamsBuilder builder=new StreamsBuilder();\n  final KStream<String,String> sourceStream=builder.stream(inputTopic,Consumed.with(Serdes.String(),Serdes.String()));\n  final KStream<String,String> mappedStream=sourceStream.selectKey((k,v) -> keyFunction.apply(v));\n  final KStream<String,Long> countStream=mappedStream.groupByKey().count(Materialized.with(Serdes.String(),Serdes.Long())).toStream();\n  mappedStream.groupByKey().aggregate(initializer,aggregator,Materialized.with(Serdes.String(),Serdes.Integer())).toStream().peek((k,v) -> System.out.println(String.format(\"AGGREGATED key=%s value=%s\",k,v))).to(aggregationTopic,Produced.with(Serdes.String(),Serdes.Integer()));\n  mappedStream.groupByKey().reduce(reducer,Materialized.with(Serdes.String(),Serdes.String())).toStream().peek((k,v) -> System.out.println(String.format(\"REDUCED key=%s value=%s\",k,v))).to(reduceTopic,Produced.with(Serdes.String(),Serdes.String()));\n  mappedStream.join(countStream,(v1,v2) -> v1 + \":\" + v2.toString(),JoinWindows.of(ofMillis(500)),StreamJoined.with(Serdes.String(),Serdes.String(),Serdes.Long())).peek((k,v) -> System.out.println(String.format(\"JOINED key=%s value=%s\",k,v))).to(joinTopic,Produced.with(Serdes.String(),Serdes.String()));\n  final Properties config=new Properties();\n  config.setProperty(StreamsConfig.APPLICATION_ID_CONFIG,\"StreamsOptimizedTest\");\n  config.setProperty(StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG,\"0\");\n  config.setProperty(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG,Serdes.String().getClass().getName());\n  config.setProperty(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG,Serdes.String().getClass().getName());\n  config.setProperty(StreamsConfig.adminClientPrefix(AdminClientConfig.RETRIES_CONFIG),\"100\");\n  config.putAll(streamsProperties);\n  final Topology topology=builder.build(config);\n  final KafkaStreams streams=new KafkaStreams(topology,config);\n  streams.setStateListener((newState,oldState) -> {\n    if (oldState == State.REBALANCING && newState == State.RUNNING) {\n      final int repartitionTopicCount=getCountOfRepartitionTopicsFound(topology.describe().toString(),repartitionTopicPattern);\n      System.out.println(String.format(\"REBALANCING -> RUNNING with REPARTITION TOPIC COUNT=%d\",repartitionTopicCount));\n      System.out.flush();\n    }\n  }\n);\n  streams.cleanUp();\n  streams.start();\n  Exit.addShutdownHook(\"streams-shutdown-hook\",() -> {\n    System.out.println(\"closing Kafka Streams instance\");\n    System.out.flush();\n    streams.close(Duration.ofMillis(5000));\n    System.out.println(\"OPTIMIZE_TEST Streams Stopped\");\n    System.out.flush();\n  }\n);\n}\n",
      "nodeType" : "Block",
      "astNodeNumber" : 645,
      "astHeight" : 13
    }, {
      "locationInParent" : "ChildListProperty[org.eclipse.jdt.core.dom.TypeDeclaration,bodyDeclarations]",
      "nodePosition" : {
        "charLength" : 4632,
        "startLineNumber" : 53,
        "startColumnNumber" : 4,
        "endLineNumber" : 144,
        "endColumnNumber" : 5
      },
      "nodeContext" : "public static void main(final String[] args) throws Exception {\n  if (args.length < 1) {\n    System.err.println(\"StreamsOptimizedTest requires one argument (properties-file) but no provided: \");\n  }\n  final String propFileName=args[0];\n  final Properties streamsProperties=Utils.loadProps(propFileName);\n  System.out.println(\"StreamsTest instance started StreamsOptimizedTest\");\n  System.out.println(\"props=\" + streamsProperties);\n  final String inputTopic=(String)Objects.requireNonNull(streamsProperties.remove(\"input.topic\"));\n  final String aggregationTopic=(String)Objects.requireNonNull(streamsProperties.remove(\"aggregation.topic\"));\n  final String reduceTopic=(String)Objects.requireNonNull(streamsProperties.remove(\"reduce.topic\"));\n  final String joinTopic=(String)Objects.requireNonNull(streamsProperties.remove(\"join.topic\"));\n  final Pattern repartitionTopicPattern=Pattern.compile(\"Sink: .*-repartition\");\n  final Initializer<Integer> initializer=() -> 0;\n  final Aggregator<String,String,Integer> aggregator=(k,v,agg) -> agg + v.length();\n  final Reducer<String> reducer=(v1,v2) -> Integer.toString(Integer.parseInt(v1) + Integer.parseInt(v2));\n  final Function<String,String> keyFunction=s -> Integer.toString(Integer.parseInt(s) % 9);\n  final StreamsBuilder builder=new StreamsBuilder();\n  final KStream<String,String> sourceStream=builder.stream(inputTopic,Consumed.with(Serdes.String(),Serdes.String()));\n  final KStream<String,String> mappedStream=sourceStream.selectKey((k,v) -> keyFunction.apply(v));\n  final KStream<String,Long> countStream=mappedStream.groupByKey().count(Materialized.with(Serdes.String(),Serdes.Long())).toStream();\n  mappedStream.groupByKey().aggregate(initializer,aggregator,Materialized.with(Serdes.String(),Serdes.Integer())).toStream().peek((k,v) -> System.out.println(String.format(\"AGGREGATED key=%s value=%s\",k,v))).to(aggregationTopic,Produced.with(Serdes.String(),Serdes.Integer()));\n  mappedStream.groupByKey().reduce(reducer,Materialized.with(Serdes.String(),Serdes.String())).toStream().peek((k,v) -> System.out.println(String.format(\"REDUCED key=%s value=%s\",k,v))).to(reduceTopic,Produced.with(Serdes.String(),Serdes.String()));\n  mappedStream.join(countStream,(v1,v2) -> v1 + \":\" + v2.toString(),JoinWindows.of(ofMillis(500)),StreamJoined.with(Serdes.String(),Serdes.String(),Serdes.Long())).peek((k,v) -> System.out.println(String.format(\"JOINED key=%s value=%s\",k,v))).to(joinTopic,Produced.with(Serdes.String(),Serdes.String()));\n  final Properties config=new Properties();\n  config.setProperty(StreamsConfig.APPLICATION_ID_CONFIG,\"StreamsOptimizedTest\");\n  config.setProperty(StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG,\"0\");\n  config.setProperty(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG,Serdes.String().getClass().getName());\n  config.setProperty(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG,Serdes.String().getClass().getName());\n  config.setProperty(StreamsConfig.adminClientPrefix(AdminClientConfig.RETRIES_CONFIG),\"100\");\n  config.putAll(streamsProperties);\n  final Topology topology=builder.build(config);\n  final KafkaStreams streams=new KafkaStreams(topology,config);\n  streams.setStateListener((newState,oldState) -> {\n    if (oldState == State.REBALANCING && newState == State.RUNNING) {\n      final int repartitionTopicCount=getCountOfRepartitionTopicsFound(topology.describe().toString(),repartitionTopicPattern);\n      System.out.println(String.format(\"REBALANCING -> RUNNING with REPARTITION TOPIC COUNT=%d\",repartitionTopicCount));\n      System.out.flush();\n    }\n  }\n);\n  streams.cleanUp();\n  streams.start();\n  Exit.addShutdownHook(\"streams-shutdown-hook\",() -> {\n    System.out.println(\"closing Kafka Streams instance\");\n    System.out.flush();\n    streams.close(Duration.ofMillis(5000));\n    System.out.println(\"OPTIMIZE_TEST Streams Stopped\");\n    System.out.flush();\n  }\n);\n}\n",
      "nodeType" : "MethodDeclaration",
      "astNodeNumber" : 659,
      "astHeight" : 14
    } ],
    "currentLineData" : {
      "locationInParent" : "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
      "nodePosition" : {
        "charLength" : 100,
        "startLineNumber" : 82,
        "startColumnNumber" : 8,
        "endLineNumber" : 82,
        "endColumnNumber" : 108
      },
      "nodeContext" : "final KStream<String,String> mappedStream=sourceStream.selectKey((k,v) -> keyFunction.apply(v));\n",
      "nodeType" : "VariableDeclarationStatement",
      "astNodeNumber" : 23,
      "astHeight" : 6
    },
    "tokenLength" : 8,
    "type" : "org.apache.kafka.streams.kstream.KStream<java.lang.String,java.lang.String>"
  } ],
  "positionList" : [ {
    "charLength" : 54,
    "startLineNumber" : 82,
    "startColumnNumber" : 53,
    "endLineNumber" : 82,
    "endColumnNumber" : 107
  } ],
  "layoutRelationDataList" : [ ]
}