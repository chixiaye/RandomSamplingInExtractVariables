{
  "id" : 452,
  "expression" : "\"        stream.fill()\\n\"",
  "projectName" : "antlr@antlr4",
  "commitID" : "f2b93e550cd912be3973743d09206db98f4092c9",
  "filePath" : "/runtime-testsuite/test/org/antlr/v4/test/runtime/python3/BasePython3Test.java",
  "occurrences" : 1,
  "isArithmeticExpression" : 0,
  "isGetTypeMethod" : 0,
  "expressionList" : [ {
    "nodeContext" : "\"        stream.fill()\\n\"",
    "nodeType" : "StringLiteral",
    "nodePosition" : {
      "charLength" : 25,
      "startLineNumber" : 41,
      "startColumnNumber" : 8,
      "endLineNumber" : 41,
      "endColumnNumber" : 33
    },
    "astNodeNumber" : 1,
    "astHeight" : 1,
    "parentDataList" : [ {
      "locationInParent" : "ChildProperty[org.eclipse.jdt.core.dom.InfixExpression,leftOperand]",
      "nodePosition" : {
        "charLength" : 543,
        "startLineNumber" : 31,
        "startColumnNumber" : 4,
        "endLineNumber" : 42,
        "endColumnNumber" : 68
      },
      "nodeContext" : "\"import sys\\n\" + \"import codecs\\n\" + \"from antlr4 import *\\n\"+ \"from <lexerName> import <lexerName>\\n\"+ \"\\n\"+ \"def main(argv):\\n\"+ \"    input = FileStream(argv[1], encoding='utf-8', errors='replace')\\n\"+ \"    with codecs.open(argv[2], 'w', 'utf-8', 'replace') as output:\\n\"+ \"        lexer = <lexerName>(input, output)\\n\"+ \"        stream = CommonTokenStream(lexer)\\n\"+ \"        stream.fill()\\n\"+ \"        [ print(t, file=output) for t in stream.tokens ]\\n\"",
      "nodeType" : "InfixExpression",
      "astNodeNumber" : 13,
      "astHeight" : 2
    }, {
      "locationInParent" : "ChildListProperty[org.eclipse.jdt.core.dom.ClassInstanceCreation,arguments]",
      "nodePosition" : {
        "charLength" : 761,
        "startLineNumber" : 31,
        "startColumnNumber" : 4,
        "endLineNumber" : 45,
        "endColumnNumber" : 37
      },
      "nodeContext" : "\"import sys\\n\" + \"import codecs\\n\" + \"from antlr4 import *\\n\"+ \"from <lexerName> import <lexerName>\\n\"+ \"\\n\"+ \"def main(argv):\\n\"+ \"    input = FileStream(argv[1], encoding='utf-8', errors='replace')\\n\"+ \"    with codecs.open(argv[2], 'w', 'utf-8', 'replace') as output:\\n\"+ \"        lexer = <lexerName>(input, output)\\n\"+ \"        stream = CommonTokenStream(lexer)\\n\"+ \"        stream.fill()\\n\"+ \"        [ print(t, file=output) for t in stream.tokens ]\\n\" + (showDFA ? \"        print(lexer._interp.decisionToDFA[Lexer.DEFAULT_MODE].toLexerString(), end='', file=output)\\n\" : \"\") + \"\\n\"+ \"if __name__ == '__main__':\\n\"+ \"    main(sys.argv)\\n\"+ \"\\n\"",
      "nodeType" : "InfixExpression",
      "astNodeNumber" : 23,
      "astHeight" : 4
    }, {
      "locationInParent" : "ChildProperty[org.eclipse.jdt.core.dom.VariableDeclarationFragment,initializer]",
      "nodePosition" : {
        "charLength" : 775,
        "startLineNumber" : 30,
        "startColumnNumber" : 20,
        "endLineNumber" : 45,
        "endColumnNumber" : 38
      },
      "nodeContext" : "new ST(\"import sys\\n\" + \"import codecs\\n\" + \"from antlr4 import *\\n\"+ \"from <lexerName> import <lexerName>\\n\"+ \"\\n\"+ \"def main(argv):\\n\"+ \"    input = FileStream(argv[1], encoding='utf-8', errors='replace')\\n\"+ \"    with codecs.open(argv[2], 'w', 'utf-8', 'replace') as output:\\n\"+ \"        lexer = <lexerName>(input, output)\\n\"+ \"        stream = CommonTokenStream(lexer)\\n\"+ \"        stream.fill()\\n\"+ \"        [ print(t, file=output) for t in stream.tokens ]\\n\" + (showDFA ? \"        print(lexer._interp.decisionToDFA[Lexer.DEFAULT_MODE].toLexerString(), end='', file=output)\\n\" : \"\") + \"\\n\"+ \"if __name__ == '__main__':\\n\"+ \"    main(sys.argv)\\n\"+ \"\\n\")",
      "nodeType" : "ClassInstanceCreation",
      "astNodeNumber" : 26,
      "astHeight" : 5
    }, {
      "locationInParent" : "ChildListProperty[org.eclipse.jdt.core.dom.VariableDeclarationStatement,fragments]",
      "nodePosition" : {
        "charLength" : 790,
        "startLineNumber" : 30,
        "startColumnNumber" : 5,
        "endLineNumber" : 45,
        "endColumnNumber" : 38
      },
      "nodeContext" : "outputFileST=new ST(\"import sys\\n\" + \"import codecs\\n\" + \"from antlr4 import *\\n\"+ \"from <lexerName> import <lexerName>\\n\"+ \"\\n\"+ \"def main(argv):\\n\"+ \"    input = FileStream(argv[1], encoding='utf-8', errors='replace')\\n\"+ \"    with codecs.open(argv[2], 'w', 'utf-8', 'replace') as output:\\n\"+ \"        lexer = <lexerName>(input, output)\\n\"+ \"        stream = CommonTokenStream(lexer)\\n\"+ \"        stream.fill()\\n\"+ \"        [ print(t, file=output) for t in stream.tokens ]\\n\" + (showDFA ? \"        print(lexer._interp.decisionToDFA[Lexer.DEFAULT_MODE].toLexerString(), end='', file=output)\\n\" : \"\") + \"\\n\"+ \"if __name__ == '__main__':\\n\"+ \"    main(sys.argv)\\n\"+ \"\\n\")",
      "nodeType" : "VariableDeclarationFragment",
      "astNodeNumber" : 28,
      "astHeight" : 6
    }, {
      "locationInParent" : "ChildListProperty[org.eclipse.jdt.core.dom.Block,statements]",
      "nodePosition" : {
        "charLength" : 794,
        "startLineNumber" : 30,
        "startColumnNumber" : 2,
        "endLineNumber" : 45,
        "endColumnNumber" : 39
      },
      "nodeContext" : "ST outputFileST=new ST(\"import sys\\n\" + \"import codecs\\n\" + \"from antlr4 import *\\n\"+ \"from <lexerName> import <lexerName>\\n\"+ \"\\n\"+ \"def main(argv):\\n\"+ \"    input = FileStream(argv[1], encoding='utf-8', errors='replace')\\n\"+ \"    with codecs.open(argv[2], 'w', 'utf-8', 'replace') as output:\\n\"+ \"        lexer = <lexerName>(input, output)\\n\"+ \"        stream = CommonTokenStream(lexer)\\n\"+ \"        stream.fill()\\n\"+ \"        [ print(t, file=output) for t in stream.tokens ]\\n\" + (showDFA ? \"        print(lexer._interp.decisionToDFA[Lexer.DEFAULT_MODE].toLexerString(), end='', file=output)\\n\" : \"\") + \"\\n\"+ \"if __name__ == '__main__':\\n\"+ \"    main(sys.argv)\\n\"+ \"\\n\");\n",
      "nodeType" : "VariableDeclarationStatement",
      "astNodeNumber" : 31,
      "astHeight" : 7
    }, {
      "locationInParent" : "ChildProperty[org.eclipse.jdt.core.dom.MethodDeclaration,body]",
      "nodePosition" : {
        "charLength" : 914,
        "startLineNumber" : 29,
        "startColumnNumber" : 70,
        "endLineNumber" : 48,
        "endColumnNumber" : 2
      },
      "nodeContext" : "{\n  ST outputFileST=new ST(\"import sys\\n\" + \"import codecs\\n\" + \"from antlr4 import *\\n\"+ \"from <lexerName> import <lexerName>\\n\"+ \"\\n\"+ \"def main(argv):\\n\"+ \"    input = FileStream(argv[1], encoding='utf-8', errors='replace')\\n\"+ \"    with codecs.open(argv[2], 'w', 'utf-8', 'replace') as output:\\n\"+ \"        lexer = <lexerName>(input, output)\\n\"+ \"        stream = CommonTokenStream(lexer)\\n\"+ \"        stream.fill()\\n\"+ \"        [ print(t, file=output) for t in stream.tokens ]\\n\" + (showDFA ? \"        print(lexer._interp.decisionToDFA[Lexer.DEFAULT_MODE].toLexerString(), end='', file=output)\\n\" : \"\") + \"\\n\"+ \"if __name__ == '__main__':\\n\"+ \"    main(sys.argv)\\n\"+ \"\\n\");\n  outputFileST.add(\"lexerName\",lexerName);\n  writeFile(getTempDirPath(),\"Test.py\",outputFileST.render());\n}\n",
      "nodeType" : "Block",
      "astNodeNumber" : 47,
      "astHeight" : 8
    }, {
      "locationInParent" : "ChildListProperty[org.eclipse.jdt.core.dom.TypeDeclaration,bodyDeclarations]",
      "nodePosition" : {
        "charLength" : 995,
        "startLineNumber" : 28,
        "startColumnNumber" : 1,
        "endLineNumber" : 48,
        "endColumnNumber" : 2
      },
      "nodeContext" : "@Override protected void writeLexerTestFile(String lexerName,boolean showDFA){\n  ST outputFileST=new ST(\"import sys\\n\" + \"import codecs\\n\" + \"from antlr4 import *\\n\"+ \"from <lexerName> import <lexerName>\\n\"+ \"\\n\"+ \"def main(argv):\\n\"+ \"    input = FileStream(argv[1], encoding='utf-8', errors='replace')\\n\"+ \"    with codecs.open(argv[2], 'w', 'utf-8', 'replace') as output:\\n\"+ \"        lexer = <lexerName>(input, output)\\n\"+ \"        stream = CommonTokenStream(lexer)\\n\"+ \"        stream.fill()\\n\"+ \"        [ print(t, file=output) for t in stream.tokens ]\\n\" + (showDFA ? \"        print(lexer._interp.decisionToDFA[Lexer.DEFAULT_MODE].toLexerString(), end='', file=output)\\n\" : \"\") + \"\\n\"+ \"if __name__ == '__main__':\\n\"+ \"    main(sys.argv)\\n\"+ \"\\n\");\n  outputFileST.add(\"lexerName\",lexerName);\n  writeFile(getTempDirPath(),\"Test.py\",outputFileST.render());\n}\n",
      "nodeType" : "MethodDeclaration",
      "astNodeNumber" : 60,
      "astHeight" : 9
    } ],
    "currentLineData" : {
      "locationInParent" : "ChildProperty[org.eclipse.jdt.core.dom.InfixExpression,leftOperand]",
      "nodePosition" : {
        "charLength" : 543,
        "startLineNumber" : 31,
        "startColumnNumber" : 4,
        "endLineNumber" : 42,
        "endColumnNumber" : 68
      },
      "nodeContext" : "\"import sys\\n\" + \"import codecs\\n\" + \"from antlr4 import *\\n\"+ \"from <lexerName> import <lexerName>\\n\"+ \"\\n\"+ \"def main(argv):\\n\"+ \"    input = FileStream(argv[1], encoding='utf-8', errors='replace')\\n\"+ \"    with codecs.open(argv[2], 'w', 'utf-8', 'replace') as output:\\n\"+ \"        lexer = <lexerName>(input, output)\\n\"+ \"        stream = CommonTokenStream(lexer)\\n\"+ \"        stream.fill()\\n\"+ \"        [ print(t, file=output) for t in stream.tokens ]\\n\"",
      "nodeType" : "InfixExpression",
      "astNodeNumber" : 13,
      "astHeight" : 2
    },
    "tokenLength" : 3,
    "type" : "java.lang.String"
  } ],
  "positionList" : [ {
    "charLength" : 25,
    "startLineNumber" : 41,
    "startColumnNumber" : 8,
    "endLineNumber" : 41,
    "endColumnNumber" : 33
  } ],
  "layoutRelationDataList" : [ ]
}